{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8j-fmdAp2_w-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5193e5f1-0c7d-4d0b-9947-dfbfc2b41acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gitf5mlC3qpB",
        "outputId": "abfb3c7a-3274-403b-bc68-a2c334fb3405"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-pbf4wcwd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-pbf4wcwd\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4304 sha256=1293fa8e2bf9c5b8df059a23e3f71f9af837727a8d049e49fb39763d65653d6b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uvpfbhv3/wheels/f3/08/cc/e2b5b0e1c92df07dbb50a6f024a68ce090f5e7b2316b41756d\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-h0qfuF31yL",
        "outputId": "ee6cab0e-8100-49bc-f321-9c4fa2aed217"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include < iostream>   // cout, endl\n",
        "#include < numeric>    // iota, fill\n",
        "\n",
        "///////////////////////////////////////////////////////////////////////////////\n",
        "// STUDENTS PART (feel free to code)\n",
        "///////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "// 2^27 float elements need 1.5 gigabytes of memory (2*0.5GB input, 0.5GB output)\n",
        "// You can set numElements to 1024 if you only want to test a single block\n",
        "// constexpr size_t numElements = 1024;\n",
        "constexpr size_t numElements = 1UL<<27;\n",
        "\n",
        "// write a kernel where each thread calculates the sum of two input values and\n",
        "// stores the result in the output array\n",
        "__global__\n",
        "void add_kernel(const float * a_in, const float * b_in, float * c_out, size_t n)\n",
        "{\n",
        "    // your code\n",
        " \n",
        "}\n",
        "\n",
        "// if you are bored try to write the kernel where each thread calculates multiple\n",
        "// additions using a for loop\n",
        "// (you have to uncomment the kernel in the main function to use it)\n",
        "__global__\n",
        "void strided_add_kernel(const float * a_in, const float * b_in, float * c_out, size_t n)\n",
        "{\n",
        "    // your code\n",
        "\n",
        "}\n",
        "\n",
        "///////////////////////////////////////////////////////////////////////////////\n",
        "// MAIN PROGRAM (take a look at what the program does)\n",
        "///////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main () {\n",
        "    // choose GPU 0 (GTX 1080 (Pascal) 8GB RAM)\n",
        "    // or GPU 1 (Titan X (Maxwell) 12GB RAM)\n",
        "    cudaSetDevice(0);                                                     \n",
        "\n",
        "    // pointers to host arrays\n",
        "    float * h_a = nullptr;\n",
        "    float * h_b = nullptr;\n",
        "    float * h_c = nullptr;\n",
        "    // pointers to device arrays\n",
        "    float * d_a = nullptr;\n",
        "    float * d_b = nullptr;\n",
        "    float * d_c = nullptr;\n",
        "\n",
        "    const size_t arraySize = sizeof(float)*numElements;\n",
        "\n",
        "    // allocate pinned host memory\n",
        "    cudaMallocHost(&h_a, arraySize);                                     \n",
        "    cudaMallocHost(&h_b, arraySize);                                     \n",
        "    cudaMallocHost(&h_c, arraySize);                                    \n",
        "\n",
        "    // allocate device memory\n",
        "    cudaMalloc(&d_a, arraySize);                                        \n",
        "    cudaMalloc(&d_b, arraySize);                                        \n",
        "    cudaMalloc(&d_c, arraySize);                                        \n",
        "\n",
        "    // fill h_a and h_b with stuff\n",
        "    std::iota(h_a, h_a+numElements, 0);             // (0, 1, 2, 3, ..., N-1)\n",
        "    std::fill(h_b, h_b+numElements, 1);             // (1, 1, 1, 1, ..., 1)\n",
        " \n",
        "    // measure time for vector addition on single-threaded host\n",
        "     for (size_t index = 0; index < numElements; index++)\n",
        "        h_c[index] = h_a[index] + h_b[index];\n",
        "  \n",
        "    // measure time for vector addition on multi-threaded host\n",
        "    for (size_t index = 0; index < numElements; index++)\n",
        "        h_c[index] = h_a[index] + h_b[index];\n",
        "    std::cout << '\\n';\n",
        "\n",
        "     // copy data from host to device\n",
        "    cudaMemcpy(d_a, h_a, arraySize, cudaMemcpyHostToDevice);             \n",
        "    cudaMemcpy(d_b, h_b, arraySize, cudaMemcpyHostToDevice);             \n",
        "  \n",
        "    // Note, the next line is not needed in practice. However, we overwrite\n",
        "    // the device vector d_c to prevent spurious false positives. As an example,\n",
        "    // if another student writes the correct result to d_c and the GPU assigns\n",
        "    // the same address range during your run (this happens quite often) then\n",
        "    // you might pass the test below even if you process nothing!\n",
        "    cudaMemset(d_c, 0, arraySize);                                      \n",
        "\n",
        "    // invoke the kernel\n",
        "    int threadsPerBlock = 1024;\n",
        "    int numBlocks = (numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    add_kernel<<< numBlocks, threadsPerBlock >>>(d_a, d_b, d_c, numElements);\n",
        " \n",
        "    // uncomment the following lines for the strided kernel\n",
        "    threadsPerBlock = 1024;\n",
        "    numBlocks = 1024;\n",
        "    strided_add_kernel<<< numBlocks, threadsPerBlock >>>(d_a, d_b, d_c, numElements);\n",
        " \n",
        "    // copy result from device to host\n",
        "     cudaMemcpy(h_c, d_c, arraySize, cudaMemcpyDeviceToHost);            \n",
        "\n",
        "     // check if result computed correctly by CUDA\n",
        "    bool no_errors = true;\n",
        "    for (size_t index = 0; index < numElements; index++) {\n",
        "        if (h_c[index] != h_a[index] + h_b[index]) {\n",
        "            std::cout << \"first error at position \" << index << std::endl;\n",
        "            no_errors = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // free memory allocations\n",
        "    cudaFreeHost(h_a);\n",
        "    cudaFreeHost(h_b);\n",
        "    cudaFreeHost(h_c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        " \n",
        "    if(no_errors)\n",
        "        std::cout << \"CUDA programming is fun!\" << std::endl;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bWp7VvZ4BB9",
        "outputId": "5f133f3f-c86b-48e7-af98-d853f8bccbae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "first error at position 0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
